# Confusion Matrix Normalized

**Confusion Matrix (матрица ошибок)** — это инструмент, который используется для оценки производительности модели классификации. Она показывает, как модель классифицирует объекты, сравнивая предсказанные метки с истинными метками. 

В библиотеке **Ultralytics**, которая предоставляет реализацию моделей YOLO (You Only Look Once), матрица ошибок часто используется для анализа качества обнаружения объектов. **Confusion Matrix Normalized** — это нормализованная версия матрицы ошибок, которая помогает лучше интерпретировать результаты.

## Что такое Confusion Matrix?

Матрица ошибок представляет собой таблицу, где:
- **Строки** соответствуют истинным классам.
- **Столбцы** соответствуют предсказанным классам.

Основные элементы матрицы:
1. **True Positive (TP)** — модель правильно предсказала класс.
2. **False Positive (FP)** — модель предсказала класс, но это неверно.
3. **False Negative (FN)** — модель не обнаружила объект, который существует.
4. **True Negative (TN)** — модель правильно определила отсутствие объекта.

Пример матрицы ошибок:

|                | Предсказано: Класс 1 | Предсказано: Класс 2 |
|----------------|----------------------|----------------------|
| **Истинный: Класс 1** | TP                   | FN                   |
| **Истинный: Класс 2** | FP                   | TN                   |


## Что такое Normalized Confusion Matrix?

**Нормализованная матрица ошибок** — это матрица, где значения представлены в виде долей или процентов относительно общего количества объектов для каждого истинного класса. Это позволяет легче сравнивать результаты между классами, особенно если количество объектов в разных классах сильно различается.

### Как рассчитывается нормализация?
Для каждого истинного класса значения в строке делятся на сумму всех значений в этой строке. Результатом является матрица, где каждая строка суммируется до 1 (или до 100%, если используются проценты).

Пример нормализации:

|                | Предсказано: Класс 1 | Предсказано: Класс 2 |
|----------------|----------------------|----------------------|
| **Истинный: Класс 1** | 0.8                  | 0.2                  |
| **Истинный: Класс 2** | 0.1                  | 0.9                  |

Здесь:
- Для истинного Класса 1: 80% объектов были правильно классифицированы, а 20% ошибочно отнесены к Классу 2.
- Для истинного Класса 2: 10% объектов были ошибочно отнесены к Классу 1, а 90% правильно классифицированы.

## Зачем использовать Normalized Confusion Matrix?

1. **Устранение дисбаланса классов**:
   Если в датасете один класс представлен значительно больше, чем другие, абсолютные значения матрицы ошибок могут быть вводящими в заблуждение. Нормализация позволяет сосредоточиться на относительной точности модели для каждого класса.

2. **Лучшая интерпретация**:
   Нормализованная матрица показывает, насколько хорошо модель работает для каждого класса, независимо от количества объектов в этом классе.

3. **Сравнение между моделями**:
   Нормализация упрощает сравнение производительности разных моделей, особенно если они обучены на разных датасетах.

## Как Ultralytics использует Normalized Confusion Matrix?

В библиотеке **Ultralytics** нормализованная матрица ошибок автоматически генерируется после завершения обучения или валидации модели. Она доступна как часть отчета о производительности модели и может быть визуализирована с помощью графиков.

### Пример использования:
После запуска обучения модели YOLOv8 с помощью скрипта `train.py`, Ultralytics выводит нормализованную матрицу ошибок в терминал или сохраняет её в виде графика в папке результатов. Это помогает понять:
- Какие классы модель классифицирует хорошо.
- Какие классы вызывают наибольшее количество ошибок.
- Есть ли систематические ошибки (например, путаница между двумя похожими классами).

## Как интерпретировать результаты?

1. **Диагональные элементы**:
   - Чем ближе значение к 1 (или 100%), тем лучше модель классифицирует этот класс.
   - Например, если для Класса 1 значение равно 0.95, это означает, что модель правильно классифицирует 95% объектов этого класса.

2. **Недиагональные элементы**:
   - Большие значения за пределами диагонали указывают на путаницу между классами.
   - Например, если для истинного Класса 1 значение в столбце "Предсказано: Класс 2" равно 0.2, это означает, что 20% объектов Класса 1 ошибочно классифицируются как Класс 2.

3. **Общая производительность**:
   - Высокие значения на диагонали и низкие значения вне диагонали говорят о хорошей производительности модели.

## Заключение

**Confusion Matrix Normalized** — это мощный инструмент для анализа производительности модели в библиотеке Ultralytics. Она помогает:
- Оценить точность модели для каждого класса.
- Выявить проблемные области (например, классы, которые часто путаются).
- Улучшить интерпретацию результатов, особенно при дисбалансе классов.

Используйте нормализованную матрицу ошибок для более глубокого понимания работы вашей модели и принятия решений о дальнейшей оптимизации.